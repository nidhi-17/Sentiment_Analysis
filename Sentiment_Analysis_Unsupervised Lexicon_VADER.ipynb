{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "775aed33",
   "metadata": {},
   "source": [
    "# Name: Nidhi Bangera \n",
    "# Project : Sentiment Analysis using NLP Libraries\n",
    "# Unsupervised Lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e0a033",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using Vader lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28badc4c",
   "metadata": {},
   "source": [
    "**Importing necessary library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c6090cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70ed97f",
   "metadata": {},
   "source": [
    "**Loading dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ec3bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one reviewer ha mentioned watching 1 oz episod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>thought wa wonderful way spend time hot summer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             review\n",
       "0          1  one reviewer ha mentioned watching 1 oz episod...\n",
       "1          1  wonderful little production filming technique ...\n",
       "2          1  thought wa wonderful way spend time hot summer...\n",
       "3          0  basically family little boy jake think zombie ...\n",
       "4          1  petter matteis love time money visually stunni..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset=pd.read_csv(r'C:\\Users\\HP\\Downloads\\movie_review.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "697d5f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['sentiment'].replace({1:'positive',0:'negative'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "add85994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_vader_lexicon(review, threshold=0.1,verbose=False):\n",
    "                                      \n",
    "    # analyze the sentiment for review\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(review)\n",
    "    # get aggregate scores and final sentiment\n",
    "    agg_score = scores['compound']\n",
    "    final_sentiment = 'positive' if agg_score >= threshold\\\n",
    "                                   else 'negative'\n",
    "    if verbose:\n",
    "        # display detailed sentiment statistics\n",
    "        positive = str(round(scores['pos'], 2)*100)+'%'\n",
    "        final = round(agg_score, 2)\n",
    "        negative = str(round(scores['neg'], 2)*100)+'%'\n",
    "        neutral = str(round(scores['neu'], 2)*100)+'%'\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, final, positive,\n",
    "                                        negative, neutral]],\n",
    "                                        columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
    "                                                                      ['Predicted Sentiment', 'Polarity Score',\n",
    "                                                                       'Positive', 'Negative', 'Neutral']], \n",
    "                                                              codes=[[0,0,0,0,0],[0,1,2,3,4]]))\n",
    "        print(sentiment_frame)\n",
    "    \n",
    "    return final_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca5d9a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505c5de4",
   "metadata": {},
   "source": [
    "**normalize data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b70b5fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = np.array(dataset['review'])\n",
    "sentiments = np.array(dataset['sentiment'])\n",
    "\n",
    "# extract data for model evaluation\n",
    "test_reviews = reviews[35000:]\n",
    "test_sentiments = sentiments[35000:]\n",
    "sample_review_ids = [7626, 3533, 13010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed857d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a30d3eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ddaf52",
   "metadata": {},
   "source": [
    "**Predict sentiment for test review**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35d80c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW: comment stupid movie acting average worse screenplay sense skip\n",
      "Actual Sentiment: negative\n",
      "     SENTIMENT STATS:                                         \n",
      "  Predicted Sentiment Polarity Score Positive Negative Neutral\n",
      "0            negative          -0.76     0.0%    48.0%   52.0%\n",
      "------------------------------------------------------------\n",
      "REVIEW: dont care people voted movie bad want truth good movie ha every thing movie really get one\n",
      "Actual Sentiment: positive\n",
      "     SENTIMENT STATS:                                         \n",
      "  Predicted Sentiment Polarity Score Positive Negative Neutral\n",
      "0            negative            0.2    34.0%    23.0%   42.0%\n",
      "------------------------------------------------------------\n",
      "REVIEW: worst horror film ever funniest film ever rolled one got see film cheap unbeliaveble see really p watch carrot\n",
      "Actual Sentiment: positive\n",
      "     SENTIMENT STATS:                                      \\\n",
      "  Predicted Sentiment Polarity Score             Positive   \n",
      "0            negative          -0.64  14.000000000000002%   \n",
      "\n",
      "                                            \n",
      "              Negative             Neutral  \n",
      "0  28.999999999999996%  56.99999999999999%  \n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
    "    print('REVIEW:', review)\n",
    "    print('Actual Sentiment:', sentiment)\n",
    "    pred = analyze_sentiment_vader_lexicon(review, threshold=0.4, verbose=True)    \n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2367b67b",
   "metadata": {},
   "source": [
    "**Evaluate model Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "309f9c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_evaluation_utils as meu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e0db67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sentiments = [analyze_sentiment_vader_lexicon(review, threshold=0.4, verbose=False) for review in test_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c33632a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.6868\n",
      "Precision: 0.7078\n",
      "Recall: 0.6868\n",
      "F1 Score: 0.6786\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.64      0.85      0.73      7510\n",
      "    negative       0.77      0.53      0.63      7490\n",
      "\n",
      "    accuracy                           0.69     15000\n",
      "   macro avg       0.71      0.69      0.68     15000\n",
      "weighted avg       0.71      0.69      0.68     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive       6357     1153\n",
      "        negative       3545     3945\n"
     ]
    }
   ],
   "source": [
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=predicted_sentiments, \n",
    "                                  classes=['positive', 'negative'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
